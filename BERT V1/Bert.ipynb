{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477},{"sourceId":9478690,"sourceType":"datasetVersion","datasetId":5765267}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"pip install --upgrade nltk","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:05:53.237059Z","iopub.execute_input":"2024-09-25T15:05:53.237507Z","iopub.status.idle":"2024-09-25T15:06:09.804351Z","shell.execute_reply.started":"2024-09-25T15:05:53.237461Z","shell.execute_reply":"2024-09-25T15:06:09.803041Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\nDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.9.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install contractions\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:09.806587Z","iopub.execute_input":"2024-09-25T15:06:09.806971Z","iopub.status.idle":"2024-09-25T15:06:23.931866Z","shell.execute_reply.started":"2024-09-25T15:06:09.806931Z","shell.execute_reply":"2024-09-25T15:06:23.930585Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting contractions\n  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting textsearch>=0.0.21 (from contractions)\n  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting anyascii (from textsearch>=0.0.21->contractions)\n  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\nCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\nDownloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\nDownloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\nDownloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\nSuccessfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:23.933373Z","iopub.execute_input":"2024-09-25T15:06:23.933723Z","iopub.status.idle":"2024-09-25T15:06:37.254952Z","shell.execute_reply.started":"2024-09-25T15:06:23.933685Z","shell.execute_reply":"2024-09-25T15:06:37.253792Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport emoji\nimport pandas as pd \nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.tokenize import RegexpTokenizer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport contractions\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:37.258558Z","iopub.execute_input":"2024-09-25T15:06:37.258934Z","iopub.status.idle":"2024-09-25T15:06:39.140074Z","shell.execute_reply.started":"2024-09-25T15:06:37.258897Z","shell.execute_reply":"2024-09-25T15:06:39.139316Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import RMSprop","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:39.141549Z","iopub.execute_input":"2024-09-25T15:06:39.142110Z","iopub.status.idle":"2024-09-25T15:06:53.520295Z","shell.execute_reply.started":"2024-09-25T15:06:39.142062Z","shell.execute_reply":"2024-09-25T15:06:53.519254Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Download NLTK resources if not already done\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('wordnet')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:53.521430Z","iopub.execute_input":"2024-09-25T15:06:53.522037Z","iopub.status.idle":"2024-09-25T15:06:53.747783Z","shell.execute_reply.started":"2024-09-25T15:06:53.522000Z","shell.execute_reply":"2024-09-25T15:06:53.746771Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Read the dataset ","metadata":{}},{"cell_type":"code","source":"# Read the CSV file with specified column names\ndf = pd.read_csv(\"/kaggle/input/positive-vs-negative-tweets/clean_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:53.749242Z","iopub.execute_input":"2024-09-25T15:06:53.749609Z","iopub.status.idle":"2024-09-25T15:06:56.477309Z","shell.execute_reply.started":"2024-09-25T15:06:53.749564Z","shell.execute_reply":"2024-09-25T15:06:56.476238Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.head (10)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:56.478880Z","iopub.execute_input":"2024-09-25T15:06:56.479799Z","iopub.status.idle":"2024-09-25T15:06:56.499808Z","shell.execute_reply.started":"2024-09-25T15:06:56.479728Z","shell.execute_reply":"2024-09-25T15:06:56.498589Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                text  target  tweet_length\n0  ['bummer', 'shoulda', 'got', 'david', 'carr', ...       0            39\n1  ['upset', 'cannot', 'update', 'facebook', 'tex...       0            76\n2  ['dived', 'many', 'time', 'ball', 'managed', '...       0            47\n3  ['whole', 'body', 'feel', 'itchy', 'like', 'fi...       0            31\n4               ['behaving', 'mad', 'cannot', 'see']       0            23\n5                                  ['whole', 'crew']       0            10\n6                                    ['need', 'hug']       0             8\n7  ['hey', 'long', 'time', 'see', 'yes', 'rain', ...       0            50\n8                                           ['nope']       0             4\n9                                   ['que', 'muera']       0             9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n      <th>tweet_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['bummer', 'shoulda', 'got', 'david', 'carr', ...</td>\n      <td>0</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['upset', 'cannot', 'update', 'facebook', 'tex...</td>\n      <td>0</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['dived', 'many', 'time', 'ball', 'managed', '...</td>\n      <td>0</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['whole', 'body', 'feel', 'itchy', 'like', 'fi...</td>\n      <td>0</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['behaving', 'mad', 'cannot', 'see']</td>\n      <td>0</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>['whole', 'crew']</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>['need', 'hug']</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>['hey', 'long', 'time', 'see', 'yes', 'rain', ...</td>\n      <td>0</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>['nope']</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>['que', 'muera']</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Select 20,000 instances of 0\ndf_1 = df[df['target'] == 1].sample(n=10000, random_state=42)\n\n# Select 20,000 instances of 0\ndf_0 = df[df['target'] == 0].sample(n=10000, random_state=42)\n\n# Concatenate the two DataFrames\nnew_df = pd.concat([df_1, df_0], ignore_index=True)\n\n# Shuffle the new DataFrame\nnew_df = new_df.sample(frac=1, random_state=42).reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:56.501141Z","iopub.execute_input":"2024-09-25T15:06:56.501459Z","iopub.status.idle":"2024-09-25T15:06:56.862711Z","shell.execute_reply.started":"2024-09-25T15:06:56.501425Z","shell.execute_reply":"2024-09-25T15:06:56.861574Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import gc\n\n# Assuming df is the name of your DataFrame\ndel df\n\n# Force garbage collection\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:56.868005Z","iopub.execute_input":"2024-09-25T15:06:56.868373Z","iopub.status.idle":"2024-09-25T15:06:57.116121Z","shell.execute_reply.started":"2024-09-25T15:06:56.868317Z","shell.execute_reply":"2024-09-25T15:06:57.115108Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"13"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming df is the name of your DataFrame\ndel df_0\n\n# Force garbage collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:57.117449Z","iopub.execute_input":"2024-09-25T15:06:57.117887Z","iopub.status.idle":"2024-09-25T15:06:57.364109Z","shell.execute_reply.started":"2024-09-25T15:06:57.117839Z","shell.execute_reply":"2024-09-25T15:06:57.363080Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming df is the name of your DataFrame\ndel df_1\n\n# Force garbage collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:57.365497Z","iopub.execute_input":"2024-09-25T15:06:57.365871Z","iopub.status.idle":"2024-09-25T15:06:57.616996Z","shell.execute_reply.started":"2024-09-25T15:06:57.365821Z","shell.execute_reply":"2024-09-25T15:06:57.615945Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"new_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:57.618837Z","iopub.execute_input":"2024-09-25T15:06:57.619171Z","iopub.status.idle":"2024-09-25T15:06:57.633117Z","shell.execute_reply.started":"2024-09-25T15:06:57.619136Z","shell.execute_reply":"2024-09-25T15:06:57.631930Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                text  target  tweet_length\n0       ['meeko', 'get', 'surgery', 'poor', 'kitty']       0            28\n1  ['really', 'excited', 'see', 'brother', 'si', ...       1            42\n2                      ['nj', 'transit', 'sympathy']       1            19\n3       ['spend', 'sunday', 'night', 'love', 'rove']       1            28\n4                      ['hoping', 'wed', 'follower']       0            19\n5      ['cannot', 'even', 'explain', 'much', 'miss']       0            29\n6  ['ood', 'snapper', 'tarakihi', 'kingfish', 'po...       0            42\n7  ['six', 'hour', 'work', 'vacation', 'time', 'h...       1            45\n8  ['finished', 'watching', 'footy', 'origin', 'a...       0            71\n9  ['call', 'text', 'next', 'hour', 'phone', 'upd...       1            38","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n      <th>tweet_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['meeko', 'get', 'surgery', 'poor', 'kitty']</td>\n      <td>0</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['really', 'excited', 'see', 'brother', 'si', ...</td>\n      <td>1</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['nj', 'transit', 'sympathy']</td>\n      <td>1</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['spend', 'sunday', 'night', 'love', 'rove']</td>\n      <td>1</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['hoping', 'wed', 'follower']</td>\n      <td>0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>['cannot', 'even', 'explain', 'much', 'miss']</td>\n      <td>0</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>['ood', 'snapper', 'tarakihi', 'kingfish', 'po...</td>\n      <td>0</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>['six', 'hour', 'work', 'vacation', 'time', 'h...</td>\n      <td>1</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>['finished', 'watching', 'footy', 'origin', 'a...</td>\n      <td>0</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>['call', 'text', 'next', 'hour', 'phone', 'upd...</td>\n      <td>1</td>\n      <td>38</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#  BERT","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:06:57.634548Z","iopub.execute_input":"2024-09-25T15:06:57.634960Z","iopub.status.idle":"2024-09-25T15:07:01.759196Z","shell.execute_reply.started":"2024-09-25T15:06:57.634919Z","shell.execute_reply":"2024-09-25T15:07:01.758173Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"texts = new_df['text'].tolist()\nlabels = new_df['target'].tolist() \n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.760525Z","iopub.execute_input":"2024-09-25T15:07:01.761208Z","iopub.status.idle":"2024-09-25T15:07:01.768480Z","shell.execute_reply.started":"2024-09-25T15:07:01.761168Z","shell.execute_reply":"2024-09-25T15:07:01.767244Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Dataset class\nclass TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer(\n            text,\n            return_tensors='pt',\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)  # Ensure labels are long type\n        }\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.769859Z","iopub.execute_input":"2024-09-25T15:07:01.770201Z","iopub.status.idle":"2024-09-25T15:07:01.789928Z","shell.execute_reply.started":"2024-09-25T15:07:01.770164Z","shell.execute_reply":"2024-09-25T15:07:01.788930Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# BERT Classifier model\nclass BERTClassifier(nn.Module):\n    def __init__(self, bert_model_name, num_classes):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        logits = self.fc(x)\n        return logits\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.791026Z","iopub.execute_input":"2024-09-25T15:07:01.791329Z","iopub.status.idle":"2024-09-25T15:07:01.800160Z","shell.execute_reply.started":"2024-09-25T15:07:01.791283Z","shell.execute_reply":"2024-09-25T15:07:01.799182Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Training function\ndef train(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    for batch in data_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.801409Z","iopub.execute_input":"2024-09-25T15:07:01.802154Z","iopub.status.idle":"2024-09-25T15:07:01.810710Z","shell.execute_reply.started":"2024-09-25T15:07:01.802119Z","shell.execute_reply":"2024-09-25T15:07:01.809800Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Evaluation function\ndef evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    \n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            \n            predictions.extend(preds.cpu().tolist())\n            actual_labels.extend(labels.cpu().tolist())\n    \n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.811882Z","iopub.execute_input":"2024-09-25T15:07:01.812231Z","iopub.status.idle":"2024-09-25T15:07:01.824686Z","shell.execute_reply.started":"2024-09-25T15:07:01.812195Z","shell.execute_reply":"2024-09-25T15:07:01.823793Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Predict function for sentiment\ndef predict_sentiment(text, model, tokenizer, device, max_length=128):\n    model.eval()\n    encoding = tokenizer(\n        text, \n        return_tensors='pt', \n        max_length=max_length, \n        padding='max_length', \n        truncation=True\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n    \n    return \"positive\" if preds.item() == 1 else \"negative\"\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.825926Z","iopub.execute_input":"2024-09-25T15:07:01.826222Z","iopub.status.idle":"2024-09-25T15:07:01.834831Z","shell.execute_reply.started":"2024-09-25T15:07:01.826189Z","shell.execute_reply":"2024-09-25T15:07:01.833953Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Set up parameters\nbert_model_name = 'bert-base-uncased'\nnum_classes = 2\nmax_length = 128\nbatch_size = 16 \nnum_epochs = 4\nlearning_rate = 2e-5\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.836087Z","iopub.execute_input":"2024-09-25T15:07:01.836384Z","iopub.status.idle":"2024-09-25T15:07:01.845045Z","shell.execute_reply.started":"2024-09-25T15:07:01.836350Z","shell.execute_reply":"2024-09-25T15:07:01.844047Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Train-test split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.846120Z","iopub.execute_input":"2024-09-25T15:07:01.846411Z","iopub.status.idle":"2024-09-25T15:07:01.869157Z","shell.execute_reply.started":"2024-09-25T15:07:01.846378Z","shell.execute_reply":"2024-09-25T15:07:01.868266Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Tokenizer\ntokenizer = BertTokenizer.from_pretrained(bert_model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:01.870482Z","iopub.execute_input":"2024-09-25T15:07:01.874318Z","iopub.status.idle":"2024-09-25T15:07:02.916370Z","shell.execute_reply.started":"2024-09-25T15:07:01.874279Z","shell.execute_reply":"2024-09-25T15:07:02.915456Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"809a8bb0157d4838acd9b511b3527ed5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce5843f167484e609c1ece660e88728f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9ff6bade95748968f2f782926b6f00f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"206156d83d584b7582a406a8656e0431"}},"metadata":{}}]},{"cell_type":"code","source":"# Datasets and Dataloaders\ntrain_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\nval_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:02.917714Z","iopub.execute_input":"2024-09-25T15:07:02.918149Z","iopub.status.idle":"2024-09-25T15:07:02.924668Z","shell.execute_reply.started":"2024-09-25T15:07:02.918101Z","shell.execute_reply":"2024-09-25T15:07:02.923552Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Device setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:02.926250Z","iopub.execute_input":"2024-09-25T15:07:02.926878Z","iopub.status.idle":"2024-09-25T15:07:02.968889Z","shell.execute_reply.started":"2024-09-25T15:07:02.926839Z","shell.execute_reply":"2024-09-25T15:07:02.967620Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Model, optimizer, and scheduler setup\nmodel = BERTClassifier(bert_model_name, num_classes).to(device)\noptimizer = AdamW(model.parameters(), lr=learning_rate)\ntotal_steps = len(train_dataloader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:02.970342Z","iopub.execute_input":"2024-09-25T15:07:02.970693Z","iopub.status.idle":"2024-09-25T15:07:09.880671Z","shell.execute_reply.started":"2024-09-25T15:07:02.970656Z","shell.execute_reply":"2024-09-25T15:07:09.879788Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f34ff3308ca84e6097120236a65d7f5c"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import time\n\n# Training loop\nfor epoch in range(num_epochs):\n    start_time = time.time()  # Start time of the epoch\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n\n    train(model, train_dataloader, optimizer, scheduler, device)\n    \n    accuracy, report = evaluate(model, val_dataloader, device)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(report)\n\n    end_time = time.time()  # End time of the epoch\n    epoch_duration = end_time - start_time  # Calculate duration\n    print(f\"Epoch {epoch + 1} Duration: {epoch_duration:.2f} seconds\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:07:09.881952Z","iopub.execute_input":"2024-09-25T15:07:09.882268Z","iopub.status.idle":"2024-09-25T15:21:24.850041Z","shell.execute_reply.started":"2024-09-25T15:07:09.882234Z","shell.execute_reply":"2024-09-25T15:21:24.848732Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/4\nValidation Accuracy: 0.7548\n              precision    recall  f1-score   support\n\n           0       0.73      0.79      0.76      1945\n           1       0.78      0.72      0.75      2055\n\n    accuracy                           0.75      4000\n   macro avg       0.76      0.76      0.75      4000\nweighted avg       0.76      0.75      0.75      4000\n\nEpoch 1 Duration: 214.12 seconds\nEpoch 2/4\nValidation Accuracy: 0.7620\n              precision    recall  f1-score   support\n\n           0       0.75      0.77      0.76      1945\n           1       0.78      0.75      0.76      2055\n\n    accuracy                           0.76      4000\n   macro avg       0.76      0.76      0.76      4000\nweighted avg       0.76      0.76      0.76      4000\n\nEpoch 2 Duration: 213.79 seconds\nEpoch 3/4\nValidation Accuracy: 0.7502\n              precision    recall  f1-score   support\n\n           0       0.74      0.75      0.75      1945\n           1       0.76      0.75      0.76      2055\n\n    accuracy                           0.75      4000\n   macro avg       0.75      0.75      0.75      4000\nweighted avg       0.75      0.75      0.75      4000\n\nEpoch 3 Duration: 213.49 seconds\nEpoch 4/4\nValidation Accuracy: 0.7480\n              precision    recall  f1-score   support\n\n           0       0.74      0.75      0.74      1945\n           1       0.76      0.75      0.75      2055\n\n    accuracy                           0.75      4000\n   macro avg       0.75      0.75      0.75      4000\nweighted avg       0.75      0.75      0.75      4000\n\nEpoch 4 Duration: 213.57 seconds\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# save the model ","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Saving the model and tokenizer\ndef save_model(model, tokenizer, model_path, tokenizer_path):\n    # Save model weights\n    torch.save(model.state_dict(), model_path)\n    \n    # Save tokenizer\n    tokenizer.save_pretrained(tokenizer_path)\n\n# Paths where you want to save the model and tokenizer\nmodel_path = \"bert_classifier_model.pth\"\ntokenizer_path = \"bert_tokenizer/\"\n\n# Save the model and tokenizer\nsave_model(model, tokenizer, model_path, tokenizer_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:21:24.855557Z","iopub.execute_input":"2024-09-25T15:21:24.855956Z","iopub.status.idle":"2024-09-25T15:21:25.734686Z","shell.execute_reply.started":"2024-09-25T15:21:24.855916Z","shell.execute_reply":"2024-09-25T15:21:25.733729Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Model and Tokenizer ","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer\n\n# Loading the model and tokenizer\ndef load_model(bert_model_name, model_path, tokenizer_path, num_classes, device):\n    # Load the tokenizer\n    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n    \n    # Initialize model\n    model = BERTClassifier(bert_model_name, num_classes).to(device)\n    \n    # Load model weights\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    \n    model.eval()  # Set the model to evaluation mode\n    return model, tokenizer\n\n# Paths to the saved model and tokenizer\nmodel_path = \"bert_classifier_model.pth\"\ntokenizer_path = \"bert_tokenizer/\"\n\n# Load the model and tokenizer\nloaded_model, loaded_tokenizer = load_model(bert_model_name, model_path, tokenizer_path, num_classes, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:21:25.736053Z","iopub.execute_input":"2024-09-25T15:21:25.736417Z","iopub.status.idle":"2024-09-25T15:21:26.583402Z","shell.execute_reply.started":"2024-09-25T15:21:25.736378Z","shell.execute_reply":"2024-09-25T15:21:26.582442Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"# Example text to predict sentiment\nexample_text = \"I love using BERT for natural language processing tasks.\"\n\n# Use the loaded model and tokenizer to predict sentiment\ndef predict_sentiment_from_loaded_model(text, model, tokenizer, device, max_length=128):\n    model.eval()\n    encoding = tokenizer(\n        text, \n        return_tensors='pt', \n        max_length=max_length, \n        padding='max_length', \n        truncation=True\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n    \n    return \"positive\" if preds.item() == 1 else \"negative\"\n\n# Predict sentiment using the loaded model\nsentiment = predict_sentiment_from_loaded_model(example_text, loaded_model, loaded_tokenizer, device)\nprint(f\"Sentiment of the example text: {sentiment}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:21:26.584735Z","iopub.execute_input":"2024-09-25T15:21:26.585107Z","iopub.status.idle":"2024-09-25T15:21:26.637149Z","shell.execute_reply.started":"2024-09-25T15:21:26.585071Z","shell.execute_reply":"2024-09-25T15:21:26.636015Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Sentiment of the example text: positive\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  gradio\n","metadata":{}},{"cell_type":"code","source":"pip install gradio\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:21:26.638349Z","iopub.execute_input":"2024-09-25T15:21:26.638708Z","iopub.status.idle":"2024-09-25T15:21:45.674217Z","shell.execute_reply.started":"2024-09-25T15:21:26.638671Z","shell.execute_reply":"2024-09-25T15:21:45.672714Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.4.0)\nRequirement already satisfied: fastapi<1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.111.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client==1.3.0 (from gradio)\n  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.0)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.4.0)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.5)\nRequirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.2)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.3.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.9.2)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.9)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.2)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit==0.12.0 (from gradio)\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.3)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\nCollecting urllib3~=2.0 (from gradio)\n  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.30.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\nRequirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.3.0->gradio) (12.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (0.37.2)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (0.0.4)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (5.10.0)\nRequirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (2.1.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.15.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.23.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\nRequirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi<1.0->gradio) (2.6.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (1.0.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.22.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\nInstalling collected packages: urllib3, tomlkit, semantic-version, ruff, ffmpy, gradio-client, gradio\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.13.2\n    Uninstalling tomlkit-0.13.2:\n      Successfully uninstalled tomlkit-0.13.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ffmpy-0.4.0 gradio-4.44.0 gradio-client-1.3.0 ruff-0.6.7 semantic-version-2.10.0 tomlkit-0.12.0 urllib3-2.2.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import gradio as gr\nimport torch\nfrom transformers import BertTokenizer\nimport torch.nn as nn\n\n# Define the model architecture (make sure this matches your saved model)\nclass BERTClassifier(nn.Module):\n    def __init__(self, bert_model_name, num_classes):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        logits = self.fc(x)\n        return logits\n\n# Function to load the model and tokenizer\ndef load_model(bert_model_name, model_path, tokenizer_path, num_classes, device):\n    # Load the tokenizer\n    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n    \n    # Initialize model\n    model = BERTClassifier(bert_model_name, num_classes).to(device)\n    \n    # Load model weights\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.eval()  # Set the model to evaluation mode\n    return model, tokenizer\n\n# Paths to the saved model and tokenizer\nmodel_path = \"bert_classifier_model.pth\"\ntokenizer_path = \"bert_tokenizer/\"\nbert_model_name = 'bert-base-uncased'\nnum_classes = 2\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load model and tokenizer\nmodel, tokenizer = load_model(bert_model_name, model_path, tokenizer_path, num_classes, device)\n\n# Function to predict sentiment\ndef predict_sentiment(text):\n    encoding = tokenizer(\n        text,\n        return_tensors='pt',\n        max_length=128,\n        padding='max_length',\n        truncation=True\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n    \n    return \"Positive\" if preds.item() == 1 else \"Negative\"\n\n# Set up the Gradio interface\ninterface = gr.Interface(\n    fn=predict_sentiment, \n    inputs=\"text\", \n    outputs=\"text\", \n    title=\"BERT Sentiment Classifier\",\n    description=\"Enter a sentence to predict its sentiment (positive/negative).\"\n)\n\n# Launch the interface\ninterface.launch(share=True)  # You can also share the link publicly\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T15:21:45.676340Z","iopub.execute_input":"2024-09-25T15:21:45.676861Z","iopub.status.idle":"2024-09-25T15:21:54.899401Z","shell.execute_reply.started":"2024-09-25T15:21:45.676804Z","shell.execute_reply":"2024-09-25T15:21:54.898347Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://844084929f9edcd918.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://844084929f9edcd918.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}